{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29700 images belonging to 11 classes.\n",
      "Found 3300 images belonging to 11 classes.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 448, 448, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 448, 448, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 448, 448, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 448, 448, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 448, 448, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 448, 448, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 224, 224, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 224, 224, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 224, 224, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 224, 224, 128)     147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 224, 224, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 224, 224, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 112, 112, 256)     295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 112, 112, 256)     1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 112, 112, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 112, 112, 256)     590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 112, 112, 256)     1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 112, 112, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 112, 112, 256)     590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 112, 112, 256)     1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 112, 112, 256)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 56, 56, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 56, 56, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 56, 56, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 56, 56, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 56, 56, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 56, 56, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 56, 56, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 56, 56, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 56, 56, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               25690368  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                2827      \n",
      "=================================================================\n",
      "Total params: 40,424,779\n",
      "Trainable params: 40,416,331\n",
      "Non-trainable params: 8,448\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/serevr/anaconda3/envs/en1/lib/python3.5/site-packages/ipykernel_launcher.py:117: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/serevr/anaconda3/envs/en1/lib/python3.5/site-packages/ipykernel_launcher.py:117: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_steps=412, validation_data=<keras.pre..., epochs=20, steps_per_epoch=3712)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3712/3712 [==============================] - 2550s 687ms/step - loss: 0.9345 - acc: 0.6513 - top_k_categorical_accuracy: 0.9624 - val_loss: 0.7183 - val_acc: 0.7130 - val_top_k_categorical_accuracy: 0.9909\n",
      "Epoch 2/20\n",
      "3712/3712 [==============================] - 2539s 684ms/step - loss: 0.4956 - acc: 0.8083 - top_k_categorical_accuracy: 0.9942 - val_loss: 0.4261 - val_acc: 0.8346 - val_top_k_categorical_accuracy: 0.9964\n",
      "Epoch 3/20\n",
      "3712/3712 [==============================] - 2542s 685ms/step - loss: 0.3655 - acc: 0.8600 - top_k_categorical_accuracy: 0.9975 - val_loss: 0.4575 - val_acc: 0.8231 - val_top_k_categorical_accuracy: 0.9979\n",
      "Epoch 4/20\n",
      "3712/3712 [==============================] - 2524s 680ms/step - loss: 0.2789 - acc: 0.8922 - top_k_categorical_accuracy: 0.9984 - val_loss: 0.3275 - val_acc: 0.8777 - val_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 5/20\n",
      "3712/3712 [==============================] - 2486s 670ms/step - loss: 0.2158 - acc: 0.9192 - top_k_categorical_accuracy: 0.9993 - val_loss: 0.3886 - val_acc: 0.8529 - val_top_k_categorical_accuracy: 0.9994\n",
      "Epoch 6/20\n",
      "3712/3712 [==============================] - 2506s 675ms/step - loss: 0.1698 - acc: 0.9378 - top_k_categorical_accuracy: 0.9995 - val_loss: 0.3768 - val_acc: 0.8647 - val_top_k_categorical_accuracy: 0.9991\n",
      "Epoch 7/20\n",
      "3712/3712 [==============================] - 2549s 687ms/step - loss: 0.1271 - acc: 0.9532 - top_k_categorical_accuracy: 0.9998 - val_loss: 0.3073 - val_acc: 0.8853 - val_top_k_categorical_accuracy: 0.9982\n",
      "Epoch 8/20\n",
      "3712/3712 [==============================] - 2550s 687ms/step - loss: 0.0910 - acc: 0.9682 - top_k_categorical_accuracy: 0.9999 - val_loss: 0.3415 - val_acc: 0.8808 - val_top_k_categorical_accuracy: 0.9994\n",
      "Epoch 9/20\n",
      "3712/3712 [==============================] - 2549s 687ms/step - loss: 0.0666 - acc: 0.9776 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3059 - val_acc: 0.8987 - val_top_k_categorical_accuracy: 0.9991\n",
      "Epoch 10/20\n",
      "3712/3712 [==============================] - 2545s 686ms/step - loss: 0.0492 - acc: 0.9849 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3739 - val_acc: 0.8871 - val_top_k_categorical_accuracy: 0.9997\n",
      "Epoch 11/20\n",
      "3712/3712 [==============================] - 2548s 686ms/step - loss: 0.0355 - acc: 0.9891 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3518 - val_acc: 0.9035 - val_top_k_categorical_accuracy: 0.9997\n",
      "Epoch 12/20\n",
      "3712/3712 [==============================] - 2545s 686ms/step - loss: 0.0256 - acc: 0.9933 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3763 - val_acc: 0.8923 - val_top_k_categorical_accuracy: 0.9997\n",
      "Epoch 13/20\n",
      "3712/3712 [==============================] - 2548s 686ms/step - loss: 0.0217 - acc: 0.9938 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3582 - val_acc: 0.9084 - val_top_k_categorical_accuracy: 0.9994\n",
      "Epoch 14/20\n",
      "3712/3712 [==============================] - 2542s 685ms/step - loss: 0.0130 - acc: 0.9972 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.2992 - val_acc: 0.9117 - val_top_k_categorical_accuracy: 0.9994\n",
      "Epoch 15/20\n",
      "3712/3712 [==============================] - 2550s 687ms/step - loss: 0.0114 - acc: 0.9973 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3005 - val_acc: 0.9144 - val_top_k_categorical_accuracy: 0.9997\n",
      "Epoch 16/20\n",
      "2301/3712 [=================>............] - ETA: 15:25 - loss: 0.0060 - acc: 0.9995 - top_k_categorical_accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "nb_train_samples = 29700\n",
    "nb_validation_samples =3300\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 448, 448\n",
    "input_shape = (448, 448, 3)\n",
    "\n",
    "img_rows, img_cols, img_channel = 448, 448, 3\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 8\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "data_generator = ImageDataGenerator(rescale=1. / 255 , validation_split=0.1)\n",
    "\n",
    "train_data_dir = '/home/serevr/Desktop/NASNET/Class11(448)'\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "   train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size, shuffle=True, seed=13,subset=\"training\",\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size, shuffle=False, seed=13,subset=\"validation\",\n",
    "    class_mode='categorical')\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding ='same', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding ='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding ='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding ='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding ='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(256, (3, 3), padding ='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(256, (3, 3), padding ='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding ='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(512, (3, 3), padding ='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(512, (3, 3), padding ='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding ='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(512, (3, 3), padding ='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(512, (3, 3), padding ='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples//batch_size + 1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "top_values, top_indices = K.get_session().run(tf.nn.top_k(y_pred, k= 5))\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer and a very slow learning rate.\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    #samples_per_epoch=3712,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=412\n",
    "    #nb_val_samples=nb_validation_samples\n",
    "    )\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting the graphs to see the loss and accuracy curves\n",
    "acc=history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss=history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper right')\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "\n",
    "#confusion Matrix and Classification Report\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples//batch_size + 1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['Boat', 'Bus','Car','Motorcycle','Planes','Suv','Tractor','Trailer','Train', 'Truck', 'Van']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
